{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81ab7635-16a7-4468-b236-256987b22b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.random import RandomState\n",
    "from pathlib import Path\n",
    "import time\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from plot_fun import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f729ba9-78ac-46b8-ad51-d5f2146a7a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_new_data = False\n",
    "load_model = True\n",
    "save_model = True\n",
    "\n",
    "# Some hyper parameters\n",
    "train_data_frac = 0.9\n",
    "batch_size = 5000\n",
    "learning_rate = 0.00005\n",
    "number_of_epochs = 10\n",
    "num_of_input = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a35302ef-b613-4e4a-91d7-4db1230f0da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path_to_save_model_to = r'saved_models\\final_model_azm_no_feature3.pth'\n",
    "path_to_load_from = r'saved_models\\final_model_azm_no_feature3.pth'\n",
    "path_to_data = r'data\\params_inc_azi.csv'\n",
    "train_path = Path(r'data\\train_data.csv')\n",
    "val_path = Path(r'data\\val_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c6d695e-4c86-4526-92f9-292e299ab994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the CPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print('Running on the GPU')\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('Running on the CPU')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3114a977-0130-4014-9197-8ba8d78dc3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path_to_data, names=['SWH', 'mean', 'var', 'azm', 'flag'])\n",
    "# Removes null values\n",
    "df.drop(df[df['SWH'].isnull()].index, inplace=True)\n",
    "rng = RandomState(4)\n",
    "\n",
    "df['mean'] = (df['mean'] - df['mean'].mean()) / (df['mean'].std())\n",
    "df['var'] = (df['var'] - df['var'].mean()) / (df['var'].std())\n",
    "df['azm'] = (df['azm'] - df['azm'].mean()) / (df['azm'].std())\n",
    "df = df[['mean', 'var', 'azm', 'SWH']]\n",
    "\n",
    "train = df.sample(frac=train_data_frac, random_state=rng)\n",
    "test = df.loc[~df.index.isin(train.index)]\n",
    "\n",
    "train_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "val_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "train.to_csv(train_path, index=False)\n",
    "test.to_csv(val_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1efe703-00cf-4c6e-9da1-984031df6722",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomCsvDataset:\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset.to(device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_data = self.dataset[idx, 0:(self.dataset.size(1) - 1)]\n",
    "        label = self.dataset[idx, self.dataset.size(1) - 1]\n",
    "        return input_data, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44fceae8-ef39-4ec5-a0a0-18cd10b09a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# the neural network\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.hid1 = torch.nn.Linear(num_of_input, 30)\n",
    "        self.hid2 = torch.nn.Linear(30, 30)\n",
    "        self.hid3 = torch.nn.Linear(30, 30)\n",
    "        self.hid4 = torch.nn.Linear(30, 30)\n",
    "        self.hid5 = torch.nn.Linear(30, 30)\n",
    "        self.hid6 = torch.nn.Linear(30, 30)\n",
    "        self.hid7 = torch.nn.Linear(30, 30)\n",
    "        self.hid8 = torch.nn.Linear(30, 30)\n",
    "        self.output = torch.nn.Linear(30, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = torch.relu(self.hid1(x))\n",
    "        z = torch.relu(self.hid2(z))\n",
    "        z = torch.relu(self.hid3(z))\n",
    "        z = torch.relu(self.hid4(z))\n",
    "        z = torch.relu(self.hid5(z))\n",
    "        z = torch.relu(self.hid6(z))\n",
    "        z = torch.relu(self.hid7(z))\n",
    "        z = torch.relu(self.hid8(z))\n",
    "        z = self.output(z)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d27a47e4-2d6c-43cc-8931-df978fb54120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (hid1): Linear(in_features=3, out_features=30, bias=True)\n",
       "  (hid2): Linear(in_features=30, out_features=30, bias=True)\n",
       "  (hid3): Linear(in_features=30, out_features=30, bias=True)\n",
       "  (hid4): Linear(in_features=30, out_features=30, bias=True)\n",
       "  (hid5): Linear(in_features=30, out_features=30, bias=True)\n",
       "  (hid6): Linear(in_features=30, out_features=30, bias=True)\n",
       "  (hid7): Linear(in_features=30, out_features=30, bias=True)\n",
       "  (hid8): Linear(in_features=30, out_features=30, bias=True)\n",
       "  (output): Linear(in_features=30, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to get results that can be repeated\n",
    "torch.manual_seed(4)\n",
    "np.random.seed(4)\n",
    "\n",
    "training_data = np.loadtxt(train_path, dtype=np.float32, delimiter=\",\", skiprows=1)\n",
    "training_data = torch.from_numpy(training_data)\n",
    "train_data = CustomCsvDataset(training_data)\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "validation_data = np.loadtxt(val_path, dtype=np.float32, delimiter=\",\", skiprows=1)\n",
    "validation_data = torch.from_numpy(validation_data)\n",
    "val_data = CustomCsvDataset(validation_data)\n",
    "val_dataloader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "net = Net().to(device)\n",
    "# loads the old model\n",
    "if load_model:\n",
    "    net.load_state_dict(torch.load(path_to_load_from, map_location=device))\n",
    "\n",
    "loss_func = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(net.parameters(), lr=learning_rate)\n",
    "net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9368dd34-8fd1-4d9e-ba6f-187aaca663dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 train loss = 2.8594005033373833\n",
      "epoch 0   val loss = 2.8594005033373833\n",
      "epoch 1 train loss = 2.85564599186182\n",
      "epoch 1   val loss = 2.85564599186182\n",
      "epoch 2 train loss = 2.854421444237232\n",
      "epoch 2   val loss = 2.854421444237232\n",
      "epoch 3 train loss = 2.852462150156498\n",
      "epoch 3   val loss = 2.852462150156498\n",
      "epoch 4 train loss = 2.857591688632965\n",
      "epoch 4   val loss = 2.857591688632965\n",
      "epoch 5 train loss = 2.8579922541975975\n",
      "epoch 5   val loss = 2.8579922541975975\n",
      "epoch 6 train loss = 2.86053204536438\n",
      "epoch 6   val loss = 2.86053204536438\n",
      "epoch 7 train loss = 2.8648892417550087\n",
      "epoch 7   val loss = 2.8648892417550087\n",
      "epoch 8 train loss = 2.85985217243433\n",
      "epoch 8   val loss = 2.85985217243433\n",
      "epoch 9 train loss = 2.858028933405876\n",
      "epoch 9   val loss = 2.858028933405876\n",
      "time for the training: 60.34988236427307\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "for epoch in range(number_of_epochs):\n",
    "    torch.manual_seed(1+epoch)  # recovery reproducibility\n",
    "    epoch_loss_train = 0.0\n",
    "    epoch_loss_val = 0.0\n",
    "\n",
    "    net.train()\n",
    "    for (idx, X) in enumerate(train_dataloader):\n",
    "        (input_data, label) = X\n",
    "        optimizer.zero_grad()\n",
    "        output = net(input_data)\n",
    "        output = torch.squeeze(output)\n",
    "        train_loss = loss_func(output, label)\n",
    "        epoch_loss_train += train_loss.item()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    net.eval()\n",
    "    for (idx, X) in enumerate(val_dataloader):\n",
    "        with torch.no_grad():\n",
    "            (input_data, label) = X\n",
    "            output = net(input_data)\n",
    "            output = torch.squeeze(output)\n",
    "            val_loss = loss_func(output, label)\n",
    "            epoch_loss_val += val_loss.item()\n",
    "\n",
    "    if epoch % 1 == 0 or epoch == number_of_epochs-1:\n",
    "        print(f'epoch {epoch} train loss = {epoch_loss_train}')\n",
    "        print(f'epoch {epoch}   val loss = {epoch_loss_train}')\n",
    "\n",
    "end_time = time.time()\n",
    "print(f'time for the training: {end_time - start_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b3129e7-154e-4e26-8d5e-f36deb59d6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, ds, ok_error):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for val_data, label in ds:\n",
    "            with torch.no_grad():\n",
    "                output = model(val_data)\n",
    "            abs_delta = np.abs(output.item()-label.item())\n",
    "            if abs_delta < ok_error:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "        acc = correct/total\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b0a8a8-b521-4666-b36e-99d7bc45749d",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "ok_error = 0.2\n",
    "train_acc = accuracy(net, train_data, ok_error)\n",
    "print(f'train accuracy: {train_acc}')\n",
    "val_acc = accuracy(net, val_data, ok_error)\n",
    "print(f'validation ({ok_error}m) accuracy: {val_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723ec22d-6e18-4fa5-9394-7cca770e5cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), path_to_save_model_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef59002f-0f59-4301-903d-fc8f048322ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_guess_vs_target_arr(model, ds):\n",
    "        model_guess_arr = np.empty(len(ds))\n",
    "        target_arr = np.empty(len(ds))\n",
    "        for i, data in enumerate(ds):\n",
    "            val_data, label = data\n",
    "            with torch.no_grad():\n",
    "                output = model(val_data)\n",
    "            target_arr[i] = label\n",
    "            model_guess_arr[i] = output\n",
    "\n",
    "        return target_arr, model_guess_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b834f2d5-2553-445f-a62b-77bba1352cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_arr, model_guess_arr = get_model_guess_vs_target_arr(net, val_data)\n",
    "# Calculates RMSE, R-value and MAE\n",
    "mse = mean_squared_error(target_arr, model_guess_arr)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"RMSE for full validation set: {rmse:.3f}\")\n",
    "\n",
    "res = r2_score(target_arr, model_guess_arr)\n",
    "res = np.sqrt(res)\n",
    "print(f\"R-value for full validation set: {res:.3f}\")\n",
    "\n",
    "mean_absolute_error = np.mean(np.abs(target_arr - model_guess_arr))\n",
    "print(f\"Mean absolute error: {mean_absolute_error:.3f}\")\n",
    "\n",
    "bias_error = np.mean(target_arr - model_guess_arr)\n",
    "print(f\"bias error: {bias_error:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dca2aa-cb5b-4675-9bf8-445f68aca68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "uncomment to plot the validation data\n",
    "plot_hist2d(target_arr, model_guess_arr)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_test] *",
   "language": "python",
   "name": "conda-env-pytorch_test-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
